{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fe0b65",
   "metadata": {},
   "source": [
    "# Vector Databases "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806c04f",
   "metadata": {},
   "source": [
    "## Comparing Similarity Metrics: Cosine Similarity vs Euclidean Distance vs Dot Product\n",
    "\n",
    "In this tutorial, we'll explore three fundamental similarity metrics used in machine learning and natural language processing:\n",
    "\n",
    "1. **Cosine Similarity** - Measures the angle between vectors (direction)\n",
    "2. **Euclidean Distance** - Measures the straight-line distance between vectors (magnitude + direction)  \n",
    "3. **Dot Product** - Measures both magnitude and direction relationship\n",
    "\n",
    "We'll use real text data with Sentence Transformers to demonstrate practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e6676d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded! Embedding dimension: 384\n",
      "Embeddings shape: (8, 384)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded! Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Sample text data for comparison\n",
    "texts = [\n",
    "    \"I love machine learning and artificial intelligence\",\n",
    "    \"Machine learning is fascinating and powerful\",\n",
    "    \"Dogs are wonderful pets and companions\", \n",
    "    \"Cats make great household pets\",\n",
    "    \"The weather is sunny and beautiful today\",\n",
    "    \"It's a gorgeous day with clear blue skies\",\n",
    "    \"Python is a great programming language\",\n",
    "    \"JavaScript is useful for web development\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(texts)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e0b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. COSINE SIMILARITY - Manual Implementation\n",
    "print(\"1. COSINE SIMILARITY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def cosine_similarity_manual(vec1, vec2):\n",
    "    \"\"\"Manual implementation of cosine similarity\"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_a = np.linalg.norm(vec1)\n",
    "    norm_b = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# Calculate cosine similarity matrix manually\n",
    "cosine_matrix = np.array([[cosine_similarity_manual(emb1, emb2) for emb2 in embeddings] for emb1 in embeddings])\n",
    "\n",
    "print(f\"Cosine similarity examples:\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[1][:30]}...': {cosine_matrix[0][1]:.4f}\")\n",
    "print(f\"'{texts[2][:30]}...' vs '{texts[3][:30]}...': {cosine_matrix[2][3]:.4f}\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[2][:30]}...': {cosine_matrix[0][2]:.4f}\")\n",
    "\n",
    "# 2. EUCLIDEAN DISTANCE - Manual Implementation  \n",
    "print(\"\\n2. EUCLIDEAN DISTANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def euclidean_distance_manual(vec1, vec2):\n",
    "    \"\"\"Manual implementation of euclidean distance\"\"\"\n",
    "    return np.sqrt(np.sum((vec1 - vec2) ** 2))\n",
    "\n",
    "# Calculate euclidean distance matrix manually\n",
    "euclidean_matrix = np.array([[euclidean_distance_manual(emb1, emb2) for emb2 in embeddings] for emb1 in embeddings])\n",
    "\n",
    "print(f\"Euclidean distance examples:\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[1][:30]}...': {euclidean_matrix[0][1]:.4f}\")\n",
    "print(f\"'{texts[2][:30]}...' vs '{texts[3][:30]}...': {euclidean_matrix[2][3]:.4f}\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[2][:30]}...': {euclidean_matrix[0][2]:.4f}\")\n",
    "\n",
    "# 3. DOT PRODUCT - Manual Implementation\n",
    "print(\"\\n3. DOT PRODUCT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate dot product matrix manually\n",
    "dot_product_matrix = np.array([[np.dot(emb1, emb2) for emb2 in embeddings] for emb1 in embeddings])\n",
    "\n",
    "print(f\"Dot product examples:\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[1][:30]}...': {dot_product_matrix[0][1]:.4f}\")\n",
    "print(f\"'{texts[2][:30]}...' vs '{texts[3][:30]}...': {dot_product_matrix[2][3]:.4f}\")\n",
    "print(f\"'{texts[0][:30]}...' vs '{texts[2][:30]}...': {dot_product_matrix[0][2]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c146e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Vector Visualization for Cosine Similarity\n",
    "print(\"2D VECTOR VISUALIZATION - Cosine Similarity in Action\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create four example texts as requested\n",
    "example_texts = [\n",
    "    \"I love machine learning and artificial intelligence\",\n",
    "    \"Machine learning is fascinating and powerful\",\n",
    "    \"Dogs are wonderful pets and companions\",\n",
    "    \"Cats make great household pets\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for the example texts\n",
    "example_embeddings = model.encode(example_texts)\n",
    "\n",
    "# Use PCA to reduce to 2D for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(example_embeddings)\n",
    "\n",
    "# Create the 2D vector plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Colors and labels for all four vectors\n",
    "colors = ['red', 'orange', 'blue', 'green']\n",
    "labels = example_texts\n",
    "\n",
    "# Plot vectors from origin\n",
    "for i, (x, y) in enumerate(embeddings_2d):\n",
    "    ax.arrow(0, 0, x, y, head_width=0.02, head_length=0.03, \n",
    "             fc=colors[i], ec=colors[i], linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Add text labels\n",
    "    ax.text(x*1.1, y*1.1, f\"{labels[i][:30]}...\", fontsize=10, fontweight='bold', \n",
    "            color=colors[i], ha='center', va='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8))\n",
    "\n",
    "# Calculate and display angles between vectors\n",
    "def calculate_angle(v1, v2):\n",
    "    \"\"\"Calculate angle between two vectors in degrees\"\"\"\n",
    "    cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    # Clip to handle numerical errors\n",
    "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
    "    angle_rad = np.arccos(cos_angle)\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "angle_ai_ml = calculate_angle(embeddings_2d[0], embeddings_2d[1])\n",
    "angle_ai_dogs = calculate_angle(embeddings_2d[0], embeddings_2d[2])\n",
    "angle_dogs_cats = calculate_angle(embeddings_2d[2], embeddings_2d[3])\n",
    "\n",
    "# Add angle annotations\n",
    "ax.text(0.05, 0.95, f'Angle Red & Orange: {angle_ai_ml:.1f}°', \n",
    "        transform=ax.transAxes, fontsize=10, \n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgray', alpha=0.8))\n",
    "ax.text(0.05, 0.90, f'Angle Red & Blue: {angle_ai_dogs:.1f}°', \n",
    "        transform=ax.transAxes, fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgray', alpha=0.8))\n",
    "ax.text(0.05, 0.85, f'Angle Blue & Green: {angle_dogs_cats:.1f}°', \n",
    "        transform=ax.transAxes, fontsize=10,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "# Styling\n",
    "ax.set_xlim(-0.6, 0.6)\n",
    "ax.set_ylim(-0.6, 0.6)\n",
    "ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax.axvline(x=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('2D Vector Visualization: Cosine Similarity in Action\\n' + \n",
    "             'Similar topics point in similar directions (small angles)', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('PCA Component 1', fontsize=12)\n",
    "ax.set_ylabel('PCA Component 2', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0c370",
   "metadata": {},
   "source": [
    "# Build and Benchmark the different FAISS Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac59a3e",
   "metadata": {},
   "source": [
    "## FAISS Benchmarking on SIFT1M Dataset\n",
    "\n",
    "We'll implement and benchmark four different FAISS indexing methods:\n",
    "1. **Flat** - Brute force exact search (baseline)\n",
    "2. **IVF** - Inverted File with clustering\n",
    "3. **HNSW** - Hierarchical Navigable Small World graphs\n",
    "4. **IVF+PQ** - IVF with Product Quantization for memory efficiency\n",
    "\n",
    "Each method will be evaluated on:\n",
    "- **Build Time** - Time to construct the index\n",
    "- **Search Time** - Time to find top-k neighbors\n",
    "- **Memory Usage** - RAM consumption\n",
    "- **Recall@1 and Recall@10** - Accuracy metrics using ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc40e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "import urllib.request as request\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0cff5",
   "metadata": {},
   "source": [
    "### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sift.tar.gz...\n",
      "Extracting archive...\n",
      "Extracting archive...\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "sift_url = \"ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz\"\n",
    "sift_archive = \"sift.tar.gz\"\n",
    "sift_dir = \"sift\"\n",
    "base_file = f\"{sift_dir}/sift_base.fvecs\"\n",
    "query_file = f\"{sift_dir}/sift_query.fvecs\"\n",
    "gt_file = f\"{sift_dir}/sift_groundtruth.ivecs\"\n",
    "len_file = f\"{sift_dir}/sift_learn.fvecs\"\n",
    "# Download and extract\n",
    "if not os.path.exists(sift_archive):\n",
    "    print(\"Downloading sift.tar.gz...\")\n",
    "    request.urlretrieve(sift_url, sift_archive)\n",
    "if not os.path.exists(base_file):\n",
    "    print(\"Extracting archive...\")\n",
    "    with tarfile.open(sift_archive, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "# Loaders\n",
    "def read_fvecs(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "        f.seek(0)\n",
    "        data = np.fromfile(f, dtype=np.float32)\n",
    "        return data.reshape(-1, d + 1)[:, 1:]\n",
    "def read_ivecs(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        d = np.fromfile(f, dtype=np.int32, count=1)[0]\n",
    "        f.seek(0)\n",
    "        data = np.fromfile(f, dtype=np.int32)\n",
    "        return data.reshape(-1, d + 1)[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a588b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SIFT1M Dataset\n",
      "Base: (1000000, 128), Query: (10000, 128), Ground Truth: (10000, 100) , Learn: (100000, 128)\n",
      "Dimension of vectors: 128\n"
     ]
    }
   ],
   "source": [
    "xb = read_fvecs(base_file)\n",
    "xq = read_fvecs(query_file)\n",
    "I_true = read_ivecs(gt_file)\n",
    "xt = read_fvecs(len_file) \n",
    "print(\"Loaded SIFT1M Dataset\")\n",
    "print(f\"Base: {xb.shape}, Query: {xq.shape}, Ground Truth: {I_true.shape} , Learn: {xt.shape}\")\n",
    "\n",
    "d = xb.shape[1]\n",
    "print(f\"Dimension of vectors: {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7628353",
   "metadata": {},
   "source": [
    "### Build the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c12966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors in index: 1,000,000\n",
      "Build time: 0.2933 seconds\n",
      "Memory usage: ~488.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Build index\n",
    "build_start = time.time()\n",
    "index_flat = faiss.IndexFlatL2(d)\n",
    "index_flat.add(xb)\n",
    "build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Vectors in index: {index_flat.ntotal:,}\")\n",
    "print(f\"Build time: {build_time:.4f} seconds\")\n",
    "print(f\"Memory usage: ~{(xb.nbytes / 1024**2):.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a7af7",
   "metadata": {},
   "source": [
    "### Perform Search on Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006fdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching 10,000 queries for top-100 neighbors...\n",
      "Search completed in 5.3535 seconds\n",
      "Performance: 1867.9 queries/sec (0.54 ms/query)\n"
     ]
    }
   ],
   "source": [
    "k = 100  \n",
    "num_queries = len(xq)  \n",
    "\n",
    "# Perform search with timing\n",
    "search_start = time.time()\n",
    "D_flat, I_flat = index_flat.search(xq, k)\n",
    "search_time = time.time() - search_start\n",
    "\n",
    "# Calculate performance metrics\n",
    "queries_per_second = num_queries / search_time\n",
    "ms_per_query = (search_time * 1000) / num_queries\n",
    "\n",
    "print(f\"Search completed in {search_time:.4f} seconds\")\n",
    "print(f\"Performance: {queries_per_second:.1f} queries/sec ({ms_per_query:.2f} ms/query)\")\n",
    "\n",
    "# Evaluate recall accuracy\n",
    "recall_at_1 = (I_flat[:, 0] == I_true[:, 0]).mean()\n",
    "recall_at_10 = np.mean([len(np.intersect1d(I_flat[i, :10], I_true[i, :10])) / 10 \n",
    "                        for i in range(num_queries)])\n",
    "\n",
    "print(f\"   Recall@1:  {recall_at_1:.4f}\")\n",
    "print(f\"   Recall@10: {recall_at_10:.4f}\")\n",
    "\n",
    "# Memory efficiency\n",
    "memory_per_vector = xb.nbytes / len(xb)\n",
    "print(f\"   Memory per vector: {memory_per_vector:.1f} bytes\")\n",
    "print(f\"   Total index size: {(xb.nbytes / 1024**2):.1f} MB\")\n",
    "\n",
    "# Store results for comparison with other methods\n",
    "flat_results = {\n",
    "    'method': 'IndexFlatL2',\n",
    "    'build_time': build_time,\n",
    "    'search_time': search_time,\n",
    "    'queries_per_second': queries_per_second,\n",
    "    'recall_at_1': recall_at_1,\n",
    "    'recall_at_10': recall_at_10,\n",
    "    'memory_mb': xb.nbytes / 1024**2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dc2a3",
   "metadata": {},
   "source": [
    "## Faster Search with Inverted File Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1e863151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build time: 22.1764 seconds\n"
     ]
    }
   ],
   "source": [
    "nlist = 4096\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # the other index\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "\n",
    "\n",
    "# Measure build time\n",
    "build_start = time.time()\n",
    "index.train(xb)  # Train the index\n",
    "index.add(xb)    # Add vectors to the index\n",
    "build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {build_time:.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800664e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search completed in 0.5132 seconds\n",
      "Performance: 19485.9 queries/sec (0.05 ms/query)\n",
      "   Recall@1:  0.8886\n",
      "   Recall@10: 0.3980\n",
      "   Memory per vector: 512.0 bytes\n",
      "   Total index size: 488.3 MB\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 16 ## Higher nprobe can improve recall but increases search time\n",
    "# Perform search with timing\n",
    "search_start = time.time()\n",
    "D_ivf, I_ivf = index.search(xq)\n",
    "search_time = time.time() - search_start\n",
    "\n",
    "# Calculate performance metrics\n",
    "queries_per_second = len(xq) / search_time\n",
    "ms_per_query = (search_time * 1000) / len(xq)\n",
    "\n",
    "print(f\"Search completed in {search_time:.4f} seconds\")\n",
    "print(f\"Performance: {queries_per_second:.1f} queries/sec ({ms_per_query:.2f} ms/query)\")\n",
    "\n",
    "# Evaluate recall accuracy\n",
    "recall_at_1_ivf = (I_ivf[:, 0] == I_true[:, 0]).mean()\n",
    "recall_at_10_ivf = np.mean([len(np.intersect1d(I_ivf[i, :10], I_true[i, :10])) / 10 \n",
    "                             for i in range(len(xq))])\n",
    "\n",
    "print(f\"   Recall@1:  {recall_at_1_ivf:.4f}\")\n",
    "print(f\"   Recall@10: {recall_at_10_ivf:.4f}\")\n",
    "\n",
    "# Memory efficiency\n",
    "memory_per_vector_ivf = xb.nbytes / len(xb)\n",
    "print(f\"   Memory per vector: {memory_per_vector_ivf:.1f} bytes\")\n",
    "print(f\"   Total index size: {(xb.nbytes / 1024**2):.1f} MB\")\n",
    "\n",
    "# Store results for comparison with other methods\n",
    "ivf_results = {\n",
    "    'method': 'IndexIVFFlat',\n",
    "    'build_time': build_time,\n",
    "    'search_time': search_time,\n",
    "    'queries_per_second': queries_per_second,\n",
    "    'recall_at_1': recall_at_1_ivf,\n",
    "    'recall_at_10': recall_at_10_ivf,\n",
    "    'memory_mb': xb.nbytes / 1024**2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb1cde",
   "metadata": {},
   "source": [
    "## Lower Memory Footprint - IVF Index with Product Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bfaef600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build time: 24.5246 seconds\n"
     ]
    }
   ],
   "source": [
    "nlist = 4096\n",
    "m = 8                             # number of subquantizers\n",
    "k = 16\n",
    "quantizer = faiss.IndexFlatL2(d)  \n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8) # 8 specifies that each sub-vector is encoded as 8 bits\n",
    "\n",
    "# Measure build time\n",
    "build_start = time.time()\n",
    "index.train(xb)  # Train the index\n",
    "index.add(xb)    # Add vectors to the index\n",
    "build_time = time.time() - build_start\n",
    "\n",
    "print(f\"Build time: {build_time:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4293c6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search completed in 0.1737 seconds\n",
      "Performance: 57584.8 queries/sec (0.02 ms/query)\n",
      "   Recall@1:  0.3022\n",
      "   Recall@10: 0.3938\n",
      "   Memory per vector: 18.3 bytes\n",
      "   Total index size: 17.4 MB\n"
     ]
    }
   ],
   "source": [
    "index.nprobe = 16 ## Higher nprobe can improve recall but increases search time\n",
    "# Perform search with timing\n",
    "search_start = time.time()\n",
    "k = 16\n",
    "D_ivfpq, I_ivfpq = index.search(xq,k)\n",
    "search_time = time.time() - search_start\n",
    "\n",
    "# Calculate performance metrics\n",
    "queries_per_second = len(xq) / search_time\n",
    "ms_per_query = (search_time * 1000) / len(xq)\n",
    "\n",
    "print(f\"Search completed in {search_time:.4f} seconds\")\n",
    "print(f\"Performance: {queries_per_second:.1f} queries/sec ({ms_per_query:.2f} ms/query)\")\n",
    "\n",
    "# Evaluate recall accuracy\n",
    "recall_at_1_ivfpq = (I_ivfpq[:, 0] == I_true[:, 0]).mean()\n",
    "recall_at_10_ivfpq = np.mean([len(np.intersect1d(I_ivfpq[i, :10], I_true[i, :10])) / 10 \n",
    "                             for i in range(len(xq))])\n",
    "\n",
    "print(f\"   Recall@1:  {recall_at_1_ivfpq:.4f}\")\n",
    "print(f\"   Recall@10: {recall_at_10_ivfpq:.4f}\")\n",
    "\n",
    "# Memory efficiency - IVF+PQ uses much less memory due to quantization\n",
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    faiss.write_index(index, tmp.name)\n",
    "    index_size_bytes = os.path.getsize(tmp.name)\n",
    "memory_mb = index_size_bytes / (1024**2)\n",
    "os.remove(tmp.name)\n",
    "\n",
    "print(f\"   Memory per vector: {(index_size_bytes / len(xb)):.1f} bytes\")\n",
    "print(f\"   Total index size: {memory_mb:.1f} MB\")\n",
    "\n",
    "# Store results for comparison with other methods\n",
    "ivfpq_results = {\n",
    "    'method': 'IndexIVFPQ',\n",
    "    'build_time': build_time,\n",
    "    'search_time': search_time,\n",
    "    'queries_per_second': queries_per_second,\n",
    "    'recall_at_1': recall_at_1_ivfpq,\n",
    "    'recall_at_10': recall_at_10_ivfpq,\n",
    "    'memory_mb': memory_mb\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c5b1d",
   "metadata": {},
   "source": [
    "## Smarter Search using HNSW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d39f6cd",
   "metadata": {},
   "source": [
    "### Testing HNSW Flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "047d3db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Time 89.90 seconds.\n"
     ]
    }
   ],
   "source": [
    "k = 16\n",
    "hnsw_index = faiss.IndexHNSWFlat(d, 32)  # 32 = number of neighbors per node\n",
    "\n",
    "# Tuning search parameters\n",
    "hnsw_index.hnsw.efConstruction = 200     # larger = better graph quality, slower build\n",
    "hnsw_index.hnsw.efSearch = 50            # larger = better recall, slower search\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "hnsw_index.add(xb)\n",
    "print(f\"Build {time.time() - start:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd01db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search completed in 0.3137 seconds\n",
      "Performance: 31882.5 queries/sec (0.03 ms/query)\n",
      "   Recall@1:  0.9760\n",
      "   Recall@10: 0.9715\n",
      "   Memory per vector: 784.1 bytes\n",
      "   Total index size: 747.8 MB\n",
      "   Memory per vector: 784.1 bytes\n",
      "   Total index size: 747.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Perform search with timing\n",
    "search_start = time.time()\n",
    "k = 16\n",
    "D_hnsw, I_hnsw = hnsw_index.search(xq, k)\n",
    "search_time = time.time() - search_start\n",
    "\n",
    "# Calculate performance metrics\n",
    "queries_per_second = len(xq) / search_time\n",
    "ms_per_query = (search_time * 1000) / len(xq)\n",
    "\n",
    "print(f\"Search completed in {search_time:.4f} seconds\")\n",
    "print(f\"Performance: {queries_per_second:.1f} queries/sec ({ms_per_query:.2f} ms/query)\")\n",
    "\n",
    "# Evaluate recall accuracy\n",
    "recall_at_1_hnsw = (I_hnsw[:, 0] == I_true[:, 0]).mean()\n",
    "recall_at_10_hnsw = np.mean([len(np.intersect1d(I_hnsw[i, :10], I_true[i, :10])) / 10 \n",
    "                             for i in range(len(xq))])\n",
    "\n",
    "print(f\"   Recall@1:  {recall_at_1_hnsw:.4f}\")\n",
    "print(f\"   Recall@10: {recall_at_10_hnsw:.4f}\")\n",
    "\n",
    "# Memory efficiency for HNSW\n",
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    faiss.write_index(hnsw_index, tmp.name)\n",
    "    index_size_bytes = os.path.getsize(tmp.name)\n",
    "memory_mb = index_size_bytes / (1024**2)\n",
    "os.remove(tmp.name)\n",
    "\n",
    "print(f\"   Memory per vector: {(index_size_bytes / len(xb)):.1f} bytes\")\n",
    "print(f\"   Total index size: {memory_mb:.1f} MB\")\n",
    "\n",
    "# Store results for comparison with other methods\n",
    "hnsw_results = {\n",
    "    'method': 'IndexHNSWFlat',\n",
    "    'build_time': time.time() - start,  # using build time from previous cell\n",
    "    'search_time': search_time,\n",
    "    'queries_per_second': queries_per_second,\n",
    "    'recall_at_1': recall_at_1_hnsw,\n",
    "    'recall_at_10': recall_at_10_hnsw,\n",
    "    'memory_mb': memory_mb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d4f63",
   "metadata": {},
   "source": [
    "## Index Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d52d8da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training index...\n",
      "Adding vectors...\n",
      "Adding vectors...\n",
      "Added 1000000 vectors in 12.68 sec\n",
      "Searching...\n",
      "Search completed in 0.09 sec\n",
      "Recall@1: 0.4429\n",
      "Recall@10: 0.9994\n",
      "Added 1000000 vectors in 12.68 sec\n",
      "Searching...\n",
      "Search completed in 0.09 sec\n",
      "Recall@1: 0.4429\n",
      "Recall@10: 0.9994\n"
     ]
    }
   ],
   "source": [
    "# Create a HNSW index with Product Quantization\n",
    "index_description = \"HNSW32,PQ16\"\n",
    "index = faiss.index_factory(d, index_description)\n",
    "\n",
    "\n",
    "if not index.is_trained:\n",
    "    print(\"Training index...\")\n",
    "    index.train(xb)  \n",
    "\n",
    "\n",
    "print(\"Adding vectors...\")\n",
    "start = time.time()\n",
    "index.add(xb)\n",
    "print(f\"Added {index.ntotal} vectors in {time.time() - start:.2f} sec\")\n",
    "\n",
    "index.hnsw.efConstruction = 200 \n",
    "index.hnsw.efSearch = 50\n",
    "\n",
    "print(\"Searching...\")\n",
    "start = time.time()\n",
    "D, I = index.search(xq, k)\n",
    "print(f\"Search completed in {time.time() - start:.2f} sec\")\n",
    "\n",
    "def compute_recall(I_pred, I_true, k):\n",
    "    match_count = sum([\n",
    "        1 if any(p in true[:k] for p in pred[:k]) else 0\n",
    "        for pred, true in zip(I_pred, I_true)\n",
    "    ])\n",
    "    return match_count / len(I_pred)\n",
    "\n",
    "recall1 = compute_recall(I, I_true, 1)\n",
    "recall10 = compute_recall(I, I_true, 10)\n",
    "\n",
    "print(f\"Recall@1: {recall1:.4f}\")\n",
    "print(f\"Recall@10: {recall10:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
